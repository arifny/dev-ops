git clone https://github.com/wardviaene/devops-box
vagrant ssh-config
https://github.com/wardviaene/terraform-course
terraform.io
download and unzip
eexporrt PATH=/user/edwardviene/terraform/:$PATH
terraform
create a user and then create an access key and secreate key
give the user administretoraccess

provider "aws"{
   access_key = "ACCESS_KEY_HERE"
   secret_key = "SECRE_KEY_HERE"
   region     = "us-east-1"
}
resourc "aws_instance" example"{
  ami       = "ami-0d729a60"
  instance_type = t2.micro"
}
terraform apply
terraform destroy to delete instance
terraform plan # shows what it is going to do
plan -out  filename
trraform apply  filename

variables
==============
provider "aws"{
   access_key = "${varAWS_ACCESS_KEY}"
   secret_key="${var.AWS_SECRET_KEY}"
   region = "${var.AWS_REGION}"
vars.tf
variable "AWS_ACCESS_KEY" {}
variable "AWS_SECRET_KEY" {}
variable "AWS_REGION"{
  dfault="us-west-1"
}
  variable "AMIS"{
     type = "map"
     defult{
       us-east-1 = "ami-13be557e"
       us-west-2 = "ami-06b94666"
       es-west-1 = "ami-0d729a60"
  ]
}
https://cloud-images.ubuntu.com/locator/ec2/
sudo apt-get install ntpdate ; ntpdate ntp.ubuntu.com
terraorm.tfrvars IN GITT IGNORE

file uploads
-----------------
resource "aws_intance" "example"{
  ami = "${lookup(var.AMIS. var.REZION)}"
  instance_type="t2.micro"
provisioner "file"{
  source = "app.conf"
  destintion = "/etc/myapp.conf"
  connection{
    user = "${var.intance_username}"
    password = "${var.instance_passworrrd}"
  }

}

wih ssh key

instance.tf
--------------
resource "aws_key_pairr" edward-key"{
 key_name="mykey"
 public_key= "ssh-rsa my-public-key"
}

resource "aws_key_pair" "mykey"{
  key_name = "mykey"
 public_key = "${file("$var.PATH_TO_PUBLIC_KEY)")}"


variable "PATH_TO_PRIVATE_KEY"{
  default = "mykey"
}
variable "PATH_TO_PUBLIC_KEY" {
  default = "mykey.pub"
}
variable "INSTANCE_USERNAME" {
   drfault = "ubuntu"
}
ssh-keygen -f key

output
----------
output "ip"{
  value = "${aws_instance.example.public_ip}
}

resource type, name and attributes

provisioner "local-exec"{
 command = "echo ${aws_insance.example.private_ip} >> prrivate_ips.txt"
 }

terraform{
 backend "consul"{
  address = "demo.consul.io" # hos6tname of consule cluster
  path + "terraform/myporject"
}
}
state in se

terraform{
  backend 's3"{
   bucket +"mybucket"
   key = "terraform/myproject"
   region ="us-east-1"
}
}

read from the file
------------------
data "terraform_remote_state" "aws-state"{
  backend = "s3"
  config {
     bucket = 'terraform-state"
      key = "terraform.tfstate"
     access_key = "${varAWS_ACESS_KEY}"
     secret_key = "$(var.AWS_SECRET_KEY}"
     region = "${vr.AWS_REGION}"
  }
}

Datasource
-------------------
   
terraorm init
 resource "aws_instance" "example"{
  ami = "${llokup(var.AMIS, var.AWS_RERGION)}"
  instance_type = "t2.micro"
  key_name = "${aws_key_pair.mykey.key_name}"
 provisioner "file"{
  source = "script.sh"
  destination = "/opt/script.sh"
  connection{
    user= "${var.instance_username}"
    private_key = "${file($9var.path_to_private_key})}"
  }
 }
}

provisioner "remote-exec"{
 inline = [
 "chomd +x /opt/script.sh",
 "/opt/script.sh arguments"
 ]
}
}    
}

AWS_ACCESS_KEY = ""
AWS_SECRT_KEY=""

instance.tf
resource "aws_instance" "emple"{
  ami = "${lookup(var.AMIS,var.AWS_RESION)}"
  instance_type="t2.micro"
AWS_REGION=""

datasource
==============

securitygroup.tf

data "aws_ip_ranges" "us_ec2"{
    regions = [ "us-east-1", "us-west-1"]
    services = ["ec2"]
resource "aws_scurity_group" "from_us"{
  name = "from_us"
  ingress {
    from_port = "443"
    to_port = "tcp"
    cidr_blocks = [ "${data.aws_ip_ranges.us_ec2.cidr_bloks}"
    SyncToken = "${data.aws_ip_ranges.us_ec2.sysnc_token}"
  }
}

template
-------------------

modules
---------

module "consul" {
   source = "github.com/wardviaene/terraform-consule-module.git"
   key_name = "${aws_key_pair.mykeey.key_name}"
   key_path = "${var.PATH_TO_PRIVATE_kEY}"

command

apply  apllies state
destroy destroy all terraform managed state
fmt  formate
get download and update module

graph visul off execution plan

import address id
output  output any resource
plan show the changes

push 
refresh
remote
show
state advance 
taint mark to destrruck
validate 
vim terraform.tfstate
terraform output
terraform taint name

vpc
=============
#internet VPC
resource "aws_vpc" "main"{
  cidr-block = "10.0.0.0/16"
  intance_tenancy = "default
 enable-dns_support = "true"
 enable_dns_hostnames = "true"
 enable_classiclink = "false"
 tags {
    Name = main"
}
}
#Subnets

resource "aws_subnet" main-public-1" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.1.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1a"
  tags {
   Name = "main-public-1"
 }
} 

resource "aws_subnet" main-public-2" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.2.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1b"
  tags {
   Name = "main-public-1"
 }
} 


resource "aws_subnet" main-public-1" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.3.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1c"
  tags {
   Name = "main-public-1"
 }
} 



resource "aws_subnet" main-private-1" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.1.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1a"
  tags {
   Name = "main-private-1"
 }
} 

resource "aws_subnet" main-private-2" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.2.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1b"
  tags {
   Name = "main-public-1"
 }
} 


resource "aws_subnet" main-private-1" {
  vpc_id ="${aws_vpc.main.id}"
  cidr_block = "10.0.3.0/24"
  map_public_ip_on_launch = "true"
  availability_zone = "us-east-1c"
  tags {
   Name = "main-private-1"
 }
} 
#Internet GW
resource "aws_internet_gateway" "main-gw"{
  vpc_id = "${aws_vpc.main.id}
  tags{
      Name = "main"
   }
}

#route tables
resource "aws_route_table" "main-public"{
   vpc_id = "${aws_vpc.mainid}"
   route {
       cidr_block = "0.0.0.0/0"
       gatrrway_id = "${aws_intrrnet_gatway.main-gw.id}"
}
  tags {
   Name = "main-public-1"
  }
}

#route association public
resource "aws_route_table_association" 'main-public-1-a"{
   subnet_id = "${ws_subnet.main-public-1.id}"
   routee_table_id = "${aws_route_table.main-public.id}"
}
resource "aws_route_table_association" 'main-public-1-b"{
   subnet_id = "${ws_subnet.main-public-2.id}"
   routee_table_id = "${aws_route_table.main-public.id}"
}
resource "aws_route_table_association" 'main-public-1-c"{
   subnet_id = "${ws_subnet.main-public-3.id}"
   routee_table_id = "${aws_route_table.main-public.id}"
}

nat.tf
#nat gw
resource "aws_epi" "nat"{
  vpc = true
}
resource "aws_nat_gatway" "nat-gw"{
  allocation_id = "${aws_epi.nat.id}"
   subnet_id = "${aws_subnet.main-public-1.id}"
   depends_on = ["aws_interrnrt_gateway.min-gw"]
}

#VPC setup for NAT
resource "aws_route_table" "main-private"{
  vpc_id = "${aws_vpc.main.id}"
  route {
     cidr_block = "0.0.0.0/0"
     nate-gateway_id = "$aws_nat_gateway.nat-gw.id}'
 }
   tags{
   Name = "main-privat-1"

#route associations private
resource "aws_route_table_association" "main-private-1-1"{
     subnet_id = "${aws-subnet.main-private-1.id}"
     route_table_id = "${aws_route_table.main-private.id}"
}
resource "aws_route_table_association" "main-private-1-2"{
     subnet_id = "${aws-subnet.main-private-2.id}"
     route_table_id = "${aws_route_table.main-private.id}"
}
resource "aws_route_table_association" "main-private-1-3"{
     subnet_id = "${aws-subnet.main-private-3.id}"
     route_table_id = "${aws_route_table.main-private.id}"
}

resource "aws_instance" "example"{
  ami = "${lookup(var.AMIS, var.AWS_REGION)}"
  instance_type = "t2.micro"
 # the VPC subnrt
 subnet_id = "${aws_subnet.main-public-1.id}"
#the securty group
vpc_security_group_ids = ["${aws_security_group.allow-ssh.id"]

# the public SSH key
key_name = "${aws_key_pair.mykeypair.key_name}"

securitygroup.tf
resource "aws_security_group" "allow-ssh"{
  vpc_id="${aws_vpc.main.id}"
  name = "allow-ssh"
  description + "security gourp that allow ssh and all egress traffic"
  egress{
   from_port=0
   to_port=0
     protocol="-1"
    cidr_blocks = ["0.0.0.0/0"]
}
 
ingress {
  from_porrt =22
  to_port = 22
  protocol ="-1"
  cidr_blocks= ["0.0.0.0/0]
}
tags{
  Name = "allow-ssh"
}
}

attaching ebs

resource "aws_instance" "example"{

}

resourc3 "aws_ebs_volume" "ebs-volume-1"{
  availability_zonw = "us-east-1a"
  size = 20
  type = "gp"
  tags {
     Name = "extra volume data"
 }
}

resource "aws_volume_attachment" ebs-volume-1-attachment"{
  deicce_name = "/dev/xvdh"
  volume_id = "${aws_ebs_volume.ebs-volume-1.id}"
  instance_id = "${aws_instance.example.id}"
}

root_block-deevice{
 volume-size = 16
  volume_type= "gp2"
  delete_on_termination = true

mkfs.ext4 /dev/xvdh

$environment="devtestexample"
$region     ="eu-west-1"
$remote_state_bucket = "${environment}-terraform-state"
$bucket_key = "yoursharedobject.$region.tfstate"

aws s3 ls "s3://$remote_state_bucket"|out-null
if ($lastexitcode)
{
   aws s3 mb "s3://$remote_state_bucket"
}

terraform remote config -backend S3 -backend-config="bucket=$remote_state_bucket"  -backend-config="key=$bucket_key" -backend-config="region=$region"
#(see here: https://www.terraform.io/docs/commands/remote-config.html)

terraform apply -var='environment=$environment' -var='region=$region'

resource "terraform_remote_state" "master_state" {
  backend = "s3"
  config {
    bucket = "${var.tf_s3_bucket}"
    region = "${var.region}"
    key = "${var.master_state_file}"
  }
}
terraform workspace new prodte
terraform workspace select default

resource "aws_vpc_peering_connection" "foo" {
  peer_owner_id = "${var.peer_owner_id}"
  peer_vpc_id   = "${aws_vpc.bar.id}"
  vpc_id        = "${aws_vpc.foo.id}"
}

variable "PATH_TO_PRIVATE_KEY" {
  default = "~/key"
}
variable "PATH_TO_PUBLIC_KEY" {
  default = "~/key.pub"
}
